{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1afc5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: C:\\ProgramData\\anaconda3\\python.exe\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (25.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (2.9.1+cpu)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp311-cp311-win_amd64.whl (662 kB)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   ---------------------------------------- 0/2 [torchvision]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   -------------------- ------------------- 1/2 [torchaudio]\n",
      "   ---------------------------------------- 2/2 [torchaudio]\n",
      "\n",
      "Successfully installed torchaudio-2.9.1+cpu torchvision-0.24.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "\n",
    "# cài torch vào ĐÚNG kernel hiện tại (CPU cho chắc ăn)\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fb1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.9.1+cpu\n",
      "device ok: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"device ok:\", \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6a0d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT = C:\\Users\\ADMIN\\Desktop\\NDM_Project\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = r\"C:\\Users\\ADMIN\\Desktop\\NDM_Project\"\n",
    "sys.path.append(os.path.join(ROOT, \"src\"))\n",
    "\n",
    "from dataio import load_splits_json, iter_segments_from_record\n",
    "from spectrogram import make_spectrogram\n",
    "\n",
    "print(\"ROOT =\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22adbd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\ADMIN\\Desktop\\NDM_Project\\configs\\cnn.json\n",
      "{'seed': 42, 'seg_len': 4096, 'hop_len': 4096, 'normalize_seg': False, 'spectrogram': {'window_type': 'hamming', 'win_length': 512, 'hop_length': 256, 'n_fft': 512, 'use_mel': True, 'mel_bins': 64, 'fmin': 0.0, 'fmax': None, 'power': 2.0, 'log_eps': 1e-08, 'to_db': False}, 'train': {'batch_size': 64, 'epochs': 25, 'lr': 0.001, 'weight_decay': 0.0001, 'early_stop_patience': 5}, 'embedding_dim': 128}\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # segment params (giống Phase 5/6 bạn đang dùng)\n",
    "    \"seg_len\": 4096,\n",
    "    \"hop_len\": 4096,\n",
    "    \"normalize_seg\": False,\n",
    "\n",
    "    # spectrogram params (đã ghi rõ theo checklist)\n",
    "    \"spectrogram\": {\n",
    "        \"window_type\": \"hamming\",\n",
    "        \"win_length\": 512,\n",
    "        \"hop_length\": 256,\n",
    "        \"n_fft\": 512,\n",
    "        \"use_mel\": True,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 0.0,\n",
    "        \"fmax\": None,\n",
    "        \"power\": 2.0,\n",
    "        \"log_eps\": 1e-8,\n",
    "        \"to_db\": False\n",
    "    },\n",
    "\n",
    "    # training\n",
    "    \"train\": {\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 25,\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"early_stop_patience\": 5\n",
    "    },\n",
    "\n",
    "    # embedding dim (deep feature)\n",
    "    \"embedding_dim\": 128\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.join(ROOT, \"configs\"), exist_ok=True)\n",
    "cfg_path = os.path.join(ROOT, \"configs\", \"cnn.json\")\n",
    "with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cfg, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", cfg_path)\n",
    "print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc987da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: {'train': 80, 'val': 10, 'test': 10}\n",
      "Meta: {'fs': 48000, 'chunk_seconds': 1.0, 'seed': 42, 'note': 'Split by non-overlapping chunks (anti-leak) before segmentation'}\n",
      "Classes: ['BF_007', 'BF_014', 'BF_021', 'H', 'IRF_007', 'IRF_014', 'IRF_021', 'ORF_007', 'ORF_014', 'ORF_021']\n",
      "Num segments: {'train': 880, 'val': 110, 'test': 110}\n"
     ]
    }
   ],
   "source": [
    "records_map, splits, meta = load_splits_json(ROOT, r\"data\\splits\\cwru_splits.json\")\n",
    "print(\"Split sizes:\", {k: len(v) for k, v in splits.items()})\n",
    "print(\"Meta:\", meta)\n",
    "\n",
    "# label list\n",
    "labels_sorted = sorted({records_map[rid][\"label\"] for rid in records_map.keys()})\n",
    "label_to_idx = {lb:i for i, lb in enumerate(labels_sorted)}\n",
    "idx_to_label = {i:lb for lb,i in label_to_idx.items()}\n",
    "num_classes = len(labels_sorted)\n",
    "\n",
    "print(\"Classes:\", labels_sorted)\n",
    "\n",
    "# build segment index: list of (record_id, seg_id_in_record, label_idx)\n",
    "def build_index(split_name):\n",
    "    seg_len = int(cfg[\"seg_len\"])\n",
    "    hop_len = int(cfg[\"hop_len\"])\n",
    "    normalize = bool(cfg[\"normalize_seg\"])\n",
    "    index = []\n",
    "    for rid in splits[split_name]:\n",
    "        rec = records_map[rid]\n",
    "        seg_iter = iter_segments_from_record(ROOT, rec, seg_len=seg_len, hop_len=hop_len, normalize=normalize)\n",
    "        s = 0\n",
    "        for _seg in seg_iter:\n",
    "            index.append((rid, s, label_to_idx[rec[\"label\"]]))\n",
    "            s += 1\n",
    "    return index\n",
    "\n",
    "train_index = build_index(\"train\")\n",
    "val_index   = build_index(\"val\")\n",
    "test_index  = build_index(\"test\")\n",
    "\n",
    "print(\"Num segments:\", {\"train\": len(train_index), \"val\": len(val_index), \"test\": len(test_index)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e18913",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_spectrogram() got an unexpected keyword argument 'mel_bins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(CWRUSpecDataset(test_index),  batch_size\u001b[38;5;241m=\u001b[39mbs, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# xem shape 1 batch\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch x:\u001b[39m\u001b[38;5;124m\"\u001b[39m, xb\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, yb\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    738\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 788\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    790\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[6], line 58\u001b[0m, in \u001b[0;36mCWRUSpecDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     56\u001b[0m segs \u001b[38;5;241m=\u001b[39m get_segments_of_record(rid)\n\u001b[0;32m     57\u001b[0m seg \u001b[38;5;241m=\u001b[39m segs[seg_id]\n\u001b[1;32m---> 58\u001b[0m S \u001b[38;5;241m=\u001b[39m compute_spec(seg, FS)                 \u001b[38;5;66;03m# (F, T)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(S)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)      \u001b[38;5;66;03m# (1, F, T)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mcompute_spec\u001b[1;34m(seg, fs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_spec\u001b[39m(seg, fs):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# seg: 1D np array\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     S \u001b[38;5;241m=\u001b[39m make_spectrogram(\n\u001b[0;32m     12\u001b[0m         seg, fs\u001b[38;5;241m=\u001b[39mfs,\n\u001b[0;32m     13\u001b[0m         window_type\u001b[38;5;241m=\u001b[39mspec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow_type\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     14\u001b[0m         win_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     15\u001b[0m         hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhop_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     16\u001b[0m         n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     17\u001b[0m         use_mel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_mel\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     18\u001b[0m         mel_bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmel_bins\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     19\u001b[0m         fmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     20\u001b[0m         fmax\u001b[38;5;241m=\u001b[39mspec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmax\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m         power\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     22\u001b[0m         log_eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_eps\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     23\u001b[0m         to_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(spec_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_db\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# per-sample normalize (không leak)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     S \u001b[38;5;241m=\u001b[39m (S \u001b[38;5;241m-\u001b[39m S\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m (S\u001b[38;5;241m.\u001b[39mstd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: make_spectrogram() got an unexpected keyword argument 'mel_bins'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(cfg[\"seed\"])\n",
    "np.random.seed(cfg[\"seed\"])\n",
    "\n",
    "spec_cfg = cfg[\"spectrogram\"]\n",
    "\n",
    "def compute_spec(seg, fs):\n",
    "    # seg: 1D np array\n",
    "    S = make_spectrogram(\n",
    "        seg, fs=fs,\n",
    "        window_type=spec_cfg[\"window_type\"],\n",
    "        win_length=int(spec_cfg[\"win_length\"]),\n",
    "        hop_length=int(spec_cfg[\"hop_length\"]),\n",
    "        n_fft=int(spec_cfg[\"n_fft\"]),\n",
    "        use_mel=bool(spec_cfg[\"use_mel\"]),\n",
    "        mel_bins=int(spec_cfg[\"mel_bins\"]),\n",
    "        fmin=float(spec_cfg[\"fmin\"]),\n",
    "        fmax=spec_cfg[\"fmax\"],\n",
    "        power=float(spec_cfg[\"power\"]),\n",
    "        log_eps=float(spec_cfg[\"log_eps\"]),\n",
    "        to_db=bool(spec_cfg[\"to_db\"]),\n",
    "    )\n",
    "    # per-sample normalize (không leak)\n",
    "    S = (S - S.mean()) / (S.std() + 1e-6)\n",
    "    return S.astype(np.float32)  # (mel_bins, frames)\n",
    "\n",
    "# tiện: map record_id -> list segments để lấy seg theo seg_id nhanh (dataset nhỏ nên cache được)\n",
    "FS = int(meta[\"fs\"])\n",
    "SEG_LEN = int(cfg[\"seg_len\"])\n",
    "HOP_LEN = int(cfg[\"hop_len\"])\n",
    "NORM_SEG = bool(cfg[\"normalize_seg\"])\n",
    "\n",
    "_record_cache = {}  # rid -> list(np.array seg)\n",
    "\n",
    "def get_segments_of_record(rid):\n",
    "    if rid in _record_cache:\n",
    "        return _record_cache[rid]\n",
    "    rec = records_map[rid]\n",
    "    segs = []\n",
    "    for seg in iter_segments_from_record(ROOT, rec, seg_len=SEG_LEN, hop_len=HOP_LEN, normalize=NORM_SEG):\n",
    "        segs.append(seg.astype(np.float32))\n",
    "    _record_cache[rid] = segs\n",
    "    return segs\n",
    "\n",
    "class CWRUSpecDataset(Dataset):\n",
    "    def __init__(self, index_list):\n",
    "        self.index = index_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        rid, seg_id, y = self.index[i]\n",
    "        segs = get_segments_of_record(rid)\n",
    "        seg = segs[seg_id]\n",
    "        S = compute_spec(seg, FS)                 # (F, T)\n",
    "        x = torch.from_numpy(S).unsqueeze(0)      # (1, F, T)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "bs = int(cfg[\"train\"][\"batch_size\"])\n",
    "train_loader = DataLoader(CWRUSpecDataset(train_index), batch_size=bs, shuffle=True,  num_workers=0)\n",
    "val_loader   = DataLoader(CWRUSpecDataset(val_index),   batch_size=bs, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(CWRUSpecDataset(test_index),  batch_size=bs, shuffle=False, num_workers=0)\n",
    "\n",
    "# xem shape 1 batch\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch x:\", xb.shape, \"Batch y:\", yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56093160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EMB_DIM = int(cfg[\"embedding_dim\"])\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.pool  = nn.MaxPool2d(2)  # giảm F,T\n",
    "\n",
    "        self.gap   = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc_emb = nn.Linear(64, emb_dim)      # embedding layer gần cuối\n",
    "        self.fc_out = nn.Linear(emb_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, return_emb=False):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        x = self.gap(x).squeeze(-1).squeeze(-1)   # (B, 64)\n",
    "        emb = F.relu(self.fc_emb(x))              # (B, emb_dim)\n",
    "        logits = self.fc_out(emb)\n",
    "\n",
    "        if return_emb:\n",
    "            return logits, emb\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = CNNBaseline(num_classes=num_classes, emb_dim=EMB_DIM).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(os.path.join(ROOT, \"results\"), exist_ok=True)\n",
    "\n",
    "def run_eval(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, total, correct = 0.0, 0, 0\n",
    "    all_y, all_p = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            total_loss += float(loss.item()) * y.size(0)\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            correct += int((pred == y).sum().item())\n",
    "            total += int(y.size(0))\n",
    "\n",
    "            all_y.append(y.cpu().numpy())\n",
    "            all_p.append(pred.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / max(total, 1)\n",
    "    acc = correct / max(total, 1)\n",
    "    all_y = np.concatenate(all_y) if len(all_y) else np.array([])\n",
    "    all_p = np.concatenate(all_p) if len(all_p) else np.array([])\n",
    "    return avg_loss, acc, all_y, all_p\n",
    "\n",
    "train_cfg = cfg[\"train\"]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=float(train_cfg[\"lr\"]), weight_decay=float(train_cfg[\"weight_decay\"]))\n",
    "\n",
    "best_val_acc = -1.0\n",
    "best_path = os.path.join(ROOT, \"results\", \"cnn_baseline.pt\")\n",
    "log_rows = []\n",
    "pat = 0\n",
    "\n",
    "epochs = int(train_cfg[\"epochs\"])\n",
    "for epoch in range(1, epochs+1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total, correct = 0.0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss.item()) * y.size(0)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += int(y.size(0))\n",
    "\n",
    "    train_loss = total_loss / max(total, 1)\n",
    "    train_acc  = correct / max(total, 1)\n",
    "\n",
    "    val_loss, val_acc, _, _ = run_eval(model, val_loader)\n",
    "\n",
    "    row = {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss, \"train_acc\": train_acc,\n",
    "        \"val_loss\": val_loss, \"val_acc\": val_acc,\n",
    "        \"sec\": time.time() - t0\n",
    "    }\n",
    "    log_rows.append(row)\n",
    "    print(f\"[{epoch:02d}] train loss {train_loss:.4f} acc {train_acc:.4f} | val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n",
    "    # early stop theo val_acc\n",
    "    if val_acc > best_val_acc + 1e-6:\n",
    "        best_val_acc = val_acc\n",
    "        pat = 0\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"labels_sorted\": labels_sorted,\n",
    "            \"cfg\": cfg,\n",
    "            \"meta\": meta\n",
    "        }, best_path)\n",
    "        print(\"  -> saved best:\", best_path)\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= int(train_cfg[\"early_stop_patience\"]):\n",
    "            print(\"Early stop.\")\n",
    "            break\n",
    "\n",
    "log_path = os.path.join(ROOT, \"results\", \"cnn_log.csv\")\n",
    "pd.DataFrame(log_rows).to_csv(log_path, index=False)\n",
    "print(\"Saved log:\", log_path)\n",
    "print(\"Best val acc:\", best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ckpt = torch.load(best_path, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_acc, y_true, y_pred = run_eval(model, test_loader)\n",
    "print(\"TEST loss:\", test_loss, \"acc:\", test_acc)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cm)\n",
    "plt.title(\"CNN baseline confusion matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(range(num_classes), labels_sorted, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(num_classes), labels_sorted)\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = os.path.join(ROOT, \"results\", \"cm_cnn.png\")\n",
    "plt.savefig(cm_path, dpi=200)\n",
    "plt.show()\n",
    "print(\"Saved:\", cm_path)\n",
    "\n",
    "metrics_path = os.path.join(ROOT, \"results\", \"cnn_metrics.csv\")\n",
    "import pandas as pd\n",
    "pd.DataFrame([{\n",
    "    \"best_val_acc\": best_val_acc,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"test_loss\": test_loss\n",
    "}]).to_csv(metrics_path, index=False)\n",
    "print(\"Saved:\", metrics_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca5812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    X_list, y_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits, emb = model(x, return_emb=True)\n",
    "            X_list.append(emb.cpu().numpy().astype(np.float32))\n",
    "            y_list.append(y.numpy().astype(np.int64))\n",
    "    X = np.vstack(X_list) if len(X_list) else np.zeros((0, EMB_DIM), np.float32)\n",
    "    y = np.concatenate(y_list) if len(y_list) else np.zeros((0,), np.int64)\n",
    "    return X, y\n",
    "\n",
    "Xtr, ytr = extract_embeddings(model, train_loader)\n",
    "Xva, yva = extract_embeddings(model, val_loader)\n",
    "Xte, yte = extract_embeddings(model, test_loader)\n",
    "\n",
    "out_dir = os.path.join(ROOT, \"results\")\n",
    "np.save(os.path.join(out_dir, \"X_train_deep.npy\"), Xtr)\n",
    "np.save(os.path.join(out_dir, \"X_val_deep.npy\"),   Xva)\n",
    "np.save(os.path.join(out_dir, \"X_test_deep.npy\"),  Xte)\n",
    "\n",
    "np.save(os.path.join(out_dir, \"y_train.npy\"), ytr)\n",
    "np.save(os.path.join(out_dir, \"y_val.npy\"),   yva)\n",
    "np.save(os.path.join(out_dir, \"y_test.npy\"),  yte)\n",
    "\n",
    "print(\"Saved deep features:\")\n",
    "print(\"  X_train_deep:\", Xtr.shape, \"y_train:\", ytr.shape)\n",
    "print(\"  X_val_deep  :\", Xva.shape, \"y_val  :\", yva.shape)\n",
    "print(\"  X_test_deep :\", Xte.shape, \"y_test :\", yte.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
